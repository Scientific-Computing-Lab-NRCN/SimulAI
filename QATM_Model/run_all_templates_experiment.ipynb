{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Lambda, Concatenate\n",
    "from keras import Model\n",
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__, tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import QATM, MyNormLayer\n",
    "from utils import compute_score, locate_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "file_dir = '/home/yonif/SimulAI/SimulationsBW3'\n",
    "sub_directories = [os.path.join(file_dir, i) for i in os.listdir(file_dir)] \n",
    "img_path = []\n",
    "for directory in sub_directories:\n",
    "    img_path.extend([os.path.join(directory, i) for i in os.listdir(directory) if '.png' in i ])\n",
    "    \n",
    "def read_gt( file_path ):\n",
    "    with open( file_path ) as IN:\n",
    "        x, y, w, h = [ eval(i) for i in IN.readline().strip().split(',')]\n",
    "    return x, y, w, h\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model( featex, alpha = 1. ):\n",
    "    T = Input( (None, None, 3), name='template_input' )\n",
    "    I = Input( (None, None, 3), name='image_input' )\n",
    "    T_feat = featex(T)\n",
    "    I_feat = featex(I)\n",
    "    I_feat, T_feat = MyNormLayer( name='norm_layer' )( [I_feat, T_feat] )\n",
    "    dist = Lambda( lambda x: tf.einsum( \"xabc,xdec->xabde\", K.l2_normalize(x[0], axis=-1), K.l2_normalize(x[1], axis=-1) ) , name=\"cosine_dist\")([ I_feat, T_feat ])\n",
    "    conf_map = QATM(alpha, name='qatm')( dist )\n",
    "    return Model( [T, I], [conf_map], name='QATM_model')\n",
    "\n",
    "def model_eval( featex, alpha=1., backup=None ):\n",
    "    '''\n",
    "    Have a backup featex in case image is too big.\n",
    "    '''\n",
    "    model = create_model( featex , alpha=alpha)\n",
    "    if backup is not None:\n",
    "        model_bkup = create_model( backup , alpha=alpha)\n",
    "    else:\n",
    "        model_bkup = model\n",
    "    gt_list, gray_list, score_list = [], [], []\n",
    "    \n",
    "    num_samples = len(img_path) // 2\n",
    "    bar = progressbar.ProgressBar(max_value=num_samples)\n",
    "    for idx in range(num_samples):\n",
    "        bar.update(idx + 1)\n",
    "        template_raw = cv2.imread( img_path[2*idx] )[...,::-1]\n",
    "        template_bbox = read_gt( gt[2*idx] )\n",
    "        x, y, w, h = [int(round(t)) for t in template_bbox]\n",
    "        template = template_raw[y:y+h, x:x+w]\n",
    "        image = cv2.imread( img_path[2*idx+1] )[...,::-1]\n",
    "        image_gt = read_gt( gt[2*idx+1] )\n",
    "        x_gt, y_gt, w_gt, h_gt = [int(round(t)) for t in image_gt]\n",
    "        \n",
    "        # process images\n",
    "        template_ = np.expand_dims(preprocess_input( template ), axis=0)\n",
    "        image_ = np.expand_dims(preprocess_input( image ) , axis=0)\n",
    "        if w*h <= 4000:\n",
    "            val = model.predict( [template_, image_] )\n",
    "        else:\n",
    "            # used when image is too big\n",
    "            val = model_bkup.predict( [template_, image_] )\n",
    "        \n",
    "        # compute geometry mean on score map\n",
    "        val = np.log( val )\n",
    "        gray = val[0,:,:,0]\n",
    "        gray = cv2.resize( gray, (image.shape[1], image.shape[0]) )\n",
    "        score = compute_score( gray, w_gt, h_gt )\n",
    "        score[score>-1e-7] = -np.inf\n",
    "        \n",
    "        gt_list.append( image_gt )\n",
    "        gray_list.append( gray )\n",
    "        score_list.append( score )\n",
    "    return score_list, gt_list, gray_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = keras.applications.vgg19.VGG19( include_top = False, weights = 'imagenet' )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def run_template_to_db(experiment_template_path):  \n",
    "    #creating the model\n",
    "    ####################################################\n",
    "     # resize conv3_4 to conv1_2\n",
    "    vgg19 = keras.applications.vgg19.VGG19( include_top = False, weights = 'imagenet' )\n",
    "    input_ = vgg19.input\n",
    "    conv1_2 = vgg19.get_layer('block1_conv2').output\n",
    "    conv3_4 = vgg19.get_layer('block3_conv4').output\n",
    "    conv3_4 = Lambda( lambda x: tf.image.resize_bilinear( x[0], size=(tf.shape(x[1])[1], tf.shape(x[1])[2]), align_corners=True), name='resized_image' )( [conv3_4, conv1_2] )\n",
    "    concat = Concatenate()( [conv1_2, conv3_4] )\n",
    "    featex = Model( [input_], [concat], name='featex' )\n",
    "    # resize conv1_2 to conv3_4, used when image size is too big\n",
    "    input_ = vgg19.input\n",
    "    conv1_2 = vgg19.get_layer('block1_conv2').output\n",
    "    conv3_4 = vgg19.get_layer('block3_conv4').output\n",
    "    conv1_2 = Lambda( lambda x: tf.image.resize_bilinear( x[1], size=(tf.shape(x[0])[1], tf.shape(x[0])[2]), align_corners=True), name='resized_image' )( [conv3_4, conv1_2] )\n",
    "    concat = Concatenate()( [conv1_2, conv3_4] )\n",
    "    featex2 = Model( [input_], [concat], name='featex2' )\n",
    "    model = create_model( featex , alpha=25)\n",
    "    model_bkup = create_model( featex2 , alpha=25)\n",
    "    \n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    template_path = experiment_template_path ################################# ASSUME IMAGES COME THRESHOLDED!\n",
    "    # load image and ground truth\n",
    "    template_raw = cv2.imread(template_path)[...,::-1]\n",
    "    x_t = 0\n",
    "    y_t = 0\n",
    "    w_t =  template_raw.shape[1]-1\n",
    "    h_t =  template_raw.shape[0]-1\n",
    "    template_plot = cv2.rectangle( template_raw.copy(), (x_t, y_t), (x_t+w_t, y_t+h_t), (0, 255,0), 1 )\n",
    "    template = template_raw[y_t:y_t+h_t, x_t:x_t+w_t]\n",
    "    \n",
    "    #we noticed that some images crash the running, so we created one json to save the data we succeeded to examine, and other json to save the paths of the bad images   \n",
    "    file_json_good = open(\"/home/yonif/SimulAI/QATM/QATM_GOOD_JSON/\" + os.path.basename(experiment_template_path)[:-4] + \".json\", \"w\")\n",
    "    file_json_bad = open(\"/home/yonif/SimulAI/QATM/QATM_BAD_JSON/\" + os.path.basename(experiment_template_path)[:-4] + \".json\", \"w\")\n",
    "    \n",
    "    count_good = 0 \n",
    "    for i in range(len(img_path)):\n",
    "        if i%100==0 and i>0:\n",
    "            t = time.localtime()\n",
    "            current_time = time.strftime(\"%H:%M:%S\", t)\n",
    "            print (experiment_template_path, count_good, i , current_time)\n",
    "        image = cv2.imread( img_path[i] )[...,::-1]\n",
    "        template_ = np.expand_dims(preprocess_input( template ), axis=0)\n",
    "        image_ = np.expand_dims(preprocess_input( image ) , axis=0)\n",
    "        try:     \n",
    "            if w_t*h_t <= 4000:             \n",
    "                val = model.predict( [template_, image_] )\n",
    "\n",
    "            else:                \n",
    "                val = model_bkup.predict( [template_, image_] )\n",
    "            # compute geometry average on score map\n",
    "            val = np.log( val )\n",
    "            gray = val[0,:,:,0]\n",
    "            gray = cv2.resize( gray, (image.shape[1], image.shape[0]) )\n",
    "            score = compute_score( gray, w_t, h_t)    \n",
    "            score[score>-1e-7] = score.min()\n",
    "            score = np.exp(score / (h_t*w_t)) # reverse number range back after computing geometry average\n",
    "            max_score, x, y, w, h = locate_bbox(score, w_t, h_t)\n",
    "                                           \n",
    "            if i == 0 :\n",
    "                file_json_good.write(\"[\" + str(max_score) + \",\\\"\" + img_path[i] + \"\\\",\" + \"(\" + str(int(x)) + \",\" + str(int(y)) + \",\" + str(int(h)) + \",\" + str(int(w))  +\"),\" + str(i) + \"]\")\n",
    "            else:\n",
    "                file_json_good.write(\",[\" + str(max_score) + \",\\\"\" + img_path[i] + \"\\\",\" + \"(\" + str(int(x)) + \",\" + str(int(y)) + \",\" + str(int(h)) + \",\" + str(int(w))  +\"),\" + str(i) + \"]\")\n",
    "\n",
    "            count_good= count_good+1  \n",
    "            \n",
    "        except:          \n",
    "            if i == 0 :            \n",
    "                file_json_bad.write(json.dumps(img_path[i]))\n",
    "            else:\n",
    "                file_json_bad.write(\",\" + json.dumps(img_path[i])) \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import singledispatch\n",
    "\n",
    "file_dir = '/home/yonif/SimulAI/SimulationsBW3'\n",
    "sub_directories = [os.path.join(file_dir, i) for i in os.listdir(file_dir)] \n",
    "img_path = []\n",
    "for directory in sub_directories:\n",
    "    img_path.extend([os.path.join(directory, i) for i in os.listdir(directory) if '.png' in i ])\n",
    " \n",
    "\n",
    "@singledispatch\n",
    "def to_serializable(val):\n",
    "    #Used by default\n",
    "    return str(val)\n",
    "\n",
    "@to_serializable.register(np.float32)\n",
    "def ts_float32(val):\n",
    "    #Used if *val* is an instance of numpy.float32.\n",
    "    return np.float64(val)\n",
    "\n",
    "\n",
    "file_dir = '/home/yonif/SimulAI/QATM/Corrected_Templates'\n",
    "os.makedirs(\"/home/yonif/SimulAI/QATM/QATM_GOOD_JSON\")\n",
    "os.makedirs(\"/home/yonif/SimulAI/QATM/QATM_BAD_JSON\")\n",
    "tasks = list()\n",
    "template_experiment_paths = [os.path.join(file_dir, i) for i in os.listdir(file_dir)]\n",
    "for path in template_experiment_paths: \n",
    "    print(\"start work on template --- \" , os.path.basename(path))\n",
    "    tasks.append(run_template_to_db.remote(path))  \n",
    "\n",
    "for task in tasks:\n",
    "    ray.get(task)\n",
    "\n",
    "print(\"done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
